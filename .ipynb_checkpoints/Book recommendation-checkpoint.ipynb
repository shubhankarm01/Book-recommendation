{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data retrieval from MySQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mysqlconnector:\n",
    "    \n",
    "    def __init__(self, database = 'book'):\n",
    "        try:\n",
    "            connection = mysql.connector.connect(host = 'localhost',\n",
    "                                                user = 'root',\n",
    "                                                password = '',\n",
    "                                                use_pure = True,\n",
    "                                                database = database\n",
    "                                                )\n",
    "            if connection.is_connected:\n",
    "                db_info = connection.get_server_info()\n",
    "                print('connected to MYSQL server version', db_info)\n",
    "                print('You are connected to the database:', database)\n",
    "                self.connection = connection\n",
    "        except Exception as e:\n",
    "            print('Error while connecting to MYSQL', e)\n",
    "            \n",
    "    def execute(self, query, header = False):\n",
    "        cursor = self.connection.cursor(buffered = True)\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        try:\n",
    "            record = cursor.fetchall()\n",
    "            \n",
    "            if header:\n",
    "                header = [i[0] for i in cursor.description]\n",
    "                return {'header': header, 'record': record}\n",
    "            else:\n",
    "                return record\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    def to_db(self, query):\n",
    "        result = self.execute(query, header = True)\n",
    "        df = pd.DataFrame(result['record'])\n",
    "        df.columns = result['header']\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mysqlconnector('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT * FROM users\n",
    "        \"\"\"\n",
    "\n",
    "df1 = db.to_db(query)\n",
    "df1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT * FROM books\n",
    "        \"\"\"\n",
    "\n",
    "df2 = db.to_db(query)\n",
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT * FROM ratings\n",
    "        \"\"\"\n",
    "\n",
    "df3 = db.to_db(query)\n",
    "df3.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape, df2.shape, df3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data cleaning and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOP cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.sort(df2['YOP'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To diplay full text in the column of the dataframe\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['book_id'] == '078946697X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['book_id'] == '2070426769']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the dataset was published on 2004 hence all the YOP above 2006(with two years of margin) can be considered as the error\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df2.loc[(df2['YOP'] > 2006) | (df2['YOP'] == 0), 'YOP'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['YOP'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publisher cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2['publisher'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['publisher'] == 'N/A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking clues from title and author for 'N/A' values\n",
    "\n",
    "df2[df2['title'] == 'Tyrant Moon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['author'] == 'Elaine Corvidae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['title'] == 'Finders Keepers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['author'] == 'Linnea Sinclair']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['age'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(df1['age'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age above 90 and below seems to be erroneous\n",
    "\n",
    "df1[(df1['age'] > 90) | (df1['age'] < 5)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings cleaning and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['book_rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching user_id from users to ratings dataset\n",
    "\n",
    "df3[df3['user_id'].isin(df1['user_id'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching book_id from books to rating dataset\n",
    "\n",
    "df3[df3['book_id'].isin(df2['book_id'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3[df3['book_id'].isin(df2['book_id'])]\n",
    "\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rating matrix should have {} entries'.format(df1.shape[0]*df2.shape[0]),'\\n',\n",
    "      'however, df4 have {} entries'.format(df4.shape[0]),'\\n',\n",
    "      'sparsity = {} %'.format(100 - df4.shape[0]*100/(df1.shape[0]*df2.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book_ratings with 0 values are implicit rating and 1-10 are explicit ratings\n",
    "\n",
    "df4_implicit = df4[df4['book_rating'] == 0]\n",
    "df4_explicit = df4[df4['book_rating'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4_implicit.shape, df4_explicit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df4_explicit['book_rating'].hist(bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(data = df4_explicit, x = 'book_rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Popularity based recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_rat = pd.DataFrame(df4_explicit.groupby('book_id')['book_rating'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_10_books = pop_rat.sort_values('book_rating', ascending = False)[:10]\n",
    "pop_10_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(pop_10_books, df2, how = 'inner', on = 'book_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Collaborative Filtering based recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making user-book rating matrix (using only explicit ratings) with reduced data\n",
    "- Only those users who have given ratings to 100 or more books\n",
    "- Only those books which has recieved aggregated 100 or more ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_explicit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = df4_explicit['user_id'].value_counts()\n",
    "\n",
    "count2 = df4_explicit['book_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user100 = count1[count1 >= 100].index\n",
    "print(len(user100))\n",
    "\n",
    "# books which have recieved atleast 100 ratings in count\n",
    "\n",
    "book100 = count2[count2 >= 100].index\n",
    "print(len(book100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All books in df4_explicit\n",
    "# df4_explicit_100 = df4_explicit[df4_explicit['user_id'].isin(user100)]\n",
    "\n",
    "# books which have recieved atleast 100 ratings in count\n",
    "df4_explicit_100 = df4_explicit[(df4_explicit['user_id'].isin(user100)) & (df4_explicit['book_id'].isin(book100))]\n",
    "\n",
    "# books with atleast 100 ratings in aggreagate\n",
    "# book100_agg = pop_rat[pop_rat['book_rating']>100].index\n",
    "# print(len(book100_agg))\n",
    "\n",
    "# df4_explicit_100 = df4_explicit[(df4_explicit['user_id'].isin(user100)) & (df4_explicit['book_id'].isin(book100_agg))]\n",
    "\n",
    "df4_explicit_100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making user-book rating matrix\n",
    "\n",
    "rating_matrix = df4_explicit_100.pivot(index = 'user_id', columns = 'book_id', values = 'book_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix = rating_matrix.astype('int32')\n",
    "\n",
    "rating_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sparsity of the rating matrix is {} %'.format((1-(rating_matrix.sum().sum())/rating_matrix.size)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_users(user_id, ratings):\n",
    "    \n",
    "#     user_ind = ratings.index.get_loc(user_id)\n",
    "    NN = NearestNeighbors()\n",
    "    NN.fit(ratings)\n",
    "    distances, indices = NN.kneighbors(ratings.loc[user_id, :].values.reshape(1, -1), n_neighbors = 10)\n",
    "    \n",
    "    similarities = 1 - distances.flatten()\n",
    "    return(similarities.flatten(), indices.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_users(2033, rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id, item_id, ratings):\n",
    "    \n",
    "    similarities, indices = similar_users(user_id, ratings)\n",
    "    \n",
    "    wtd_sum = 0\n",
    "    \n",
    "    item_ind = rating_matrix.columns.get_loc(item_id)\n",
    "    user_ind = rating_matrix.index.get_loc(user_id)\n",
    "    \n",
    "    for i in range(len(indices)):\n",
    "        if indices[i] == user_ind:\n",
    "            continue\n",
    "        else:\n",
    "            wtd_sum = wtd_sum + ((ratings.iloc[indices[i], item_ind] - rating_matrix.iloc[indices[i]].mean())*similarities[i])\n",
    "    \n",
    "    wtd_sum = wtd_sum + rating_matrix.iloc[user_ind].mean()\n",
    "    predicted_rating = wtd_sum/(similarities.sum() - 1)\n",
    "    \n",
    "    if predicted_rating < 0:\n",
    "        predicted_rating = 0\n",
    "    elif predicted_rating > 10:\n",
    "        predicted_rating = 10\n",
    "        \n",
    "#     print(predicted_rating)\n",
    "    return(predicted_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rating(2033, '0060392452', rating_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To check predicted rating for specific user_id and book_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NearestNeighbors()\n",
    "NN.fit(rating_matrix)\n",
    "distances, indices = NN.kneighbors(rating_matrix.loc[2033, :].values.reshape(1, -1), n_neighbors = 10)\n",
    "    \n",
    "similarities = 1 - distances.flatten()\n",
    "indices = indices.flatten()\n",
    "\n",
    "wtd_sum = 0\n",
    "    \n",
    "item_ind = rating_matrix.columns.get_loc('043935806X')\n",
    "user_ind = rating_matrix.index.get_loc(2033)    \n",
    "    \n",
    "for i in range(len(indices)):\n",
    "    if indices[i] == user_ind:\n",
    "        continue\n",
    "    else:\n",
    "        wtd_sum = wtd_sum + ((rating_matrix.iloc[indices[i], item_ind] - rating_matrix.iloc[indices[i]].mean())*similarities[i])\n",
    "\n",
    "wtd_sum = rating_matrix.iloc[user_ind].mean() + wtd_sum\n",
    "predicted_rating = wtd_sum/(similarities.sum() - 1)\n",
    "\n",
    "if predicted_rating < 0:\n",
    "    predicted_rating = 0\n",
    "elif predicted_rating > 10:\n",
    "    predicted_rating = 10\n",
    "        \n",
    "print(predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To check predicted rating of specific user_id and all book_id in the rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NN = NearestNeighbors()\n",
    "NN.fit(rating_matrix)\n",
    "distances, indices = NN.kneighbors(rating_matrix.loc[2033, :].values.reshape(1, -1), n_neighbors = 10)\n",
    "    \n",
    "similarities = 1 - distances.flatten()\n",
    "indices = indices.flatten()\n",
    "\n",
    "user_ind = rating_matrix.index.get_loc(2033)\n",
    "\n",
    "for j in rating_matrix.columns:\n",
    "    wtd_sum = 0\n",
    "    item_ind = rating_matrix.columns.get_loc(j)\n",
    "    for i in range(len(indices)):\n",
    "        if indices[i] == user_ind:\n",
    "            continue\n",
    "        else:\n",
    "#             wtd_sum = wtd_sum + ((rating_matrix.iloc[indices[i], item_ind])*similarities[i])\n",
    "\n",
    "#             when optimistic and passimistic users influence on predicted rating is considered\n",
    "            wtd_sum = wtd_sum + ((rating_matrix.iloc[indices[i], item_ind] - rating_matrix.iloc[indices[i]].mean())*similarities[i])\n",
    "    \n",
    "    wtd_sum = rating_matrix.iloc[user_ind].mean() + wtd_sum\n",
    "    predicted_rating = wtd_sum/(similarities.sum() - 1)\n",
    "\n",
    "    if predicted_rating < 0:\n",
    "        predicted_rating = 0\n",
    "    elif predicted_rating > 10:\n",
    "        predicted_rating = 10\n",
    "        \n",
    "    print(predicted_rating, item_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ignore userwarnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To print user_id, top 10 predicted rating and book_id for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def topn_recommendation(user_id, rating_matrix):\n",
    "    \n",
    "#     rating_prediction = []\n",
    "#     for i in rating_matrix.columns:\n",
    "#         rating_prediction.append(predict_rating(user_id, i,  rating_matrix))\n",
    "#     return(rating_prediction)\n",
    "\n",
    "# for j in rating_matrix.index:\n",
    "#     x = topn_recommendation(j, rating_matrix)\n",
    "#     y = np.argsort(x)[::-1][:10]\n",
    "    \n",
    "#     print(j, '\\n', sorted(x, reverse = True)[:10], '\\n', rating_matrix.columns[y].values, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topn_recommendation(user_id, rating_matrix):\n",
    "    \n",
    "    predicted_rating_all_items = []\n",
    "    for i in rating_matrix.columns:\n",
    "        predicted_rating_all_items.append(predict_rating(user_id, i,  rating_matrix))\n",
    "   \n",
    "#     predicted_rating_top10 = sorted(predicted_rating_all_items, reverse = True)[:10]\n",
    "    top_10_recomm_index = np.argsort(predicted_rating_all_items)[::-1][:10]\n",
    "    top_10_recomm_bookid = rating_matrix.columns[top_10_recomm_index].values\n",
    "    top_10_recomm_title = df2[df2['book_id'].isin(top_10_recomm_bookid.tolist())]['title'].values\n",
    "    \n",
    "    return(top_10_recomm_title.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn_recommendation(2276, rating_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Collaborative Filtering with LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = df4_explicit['user_id'].value_counts()\n",
    "\n",
    "count2 = df4_explicit['book_id'].value_counts()\n",
    "\n",
    "\n",
    "user20 = count1[count1 >= 20].index\n",
    "print(len(user20))\n",
    "\n",
    "# books which have recieved atleast 20 ratings in count\n",
    "\n",
    "book20 = count2[count2 >= 20].index\n",
    "print(len(book20))\n",
    "\n",
    "\n",
    "\n",
    "# books which have recieved atleast 100 ratings in count\n",
    "\n",
    "df4_explicit_20 = df4_explicit[(df4_explicit['user_id'].isin(user20)) & (df4_explicit['book_id'].isin(book20))]\n",
    "\n",
    "df4_explicit_20.head()\n",
    "\n",
    "# Making user-book rating matrix\n",
    "\n",
    "# rating_matrix = df4_explicit_20.pivot(index = 'user_id', columns = 'book_id', values = 'book_rating')\n",
    "\n",
    "# rating_matrix.fillna(0, inplace = True)\n",
    "\n",
    "# rating_matrix = rating_matrix.astype('int32')\n",
    "\n",
    "# rating_matrix.head()\n",
    "\n",
    "# print('sparsity of the rating matrix is {} %'.format((1-(rating_matrix.sum().sum())/rating_matrix.size)*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to give train and test coordinate matrices and train matrix in raw form (df3 form)\n",
    "\n",
    "def train_test_rawtrain(df4_explicit_20, train_ratio):\n",
    "    \n",
    "    rows_in_split1 = int(df4_explicit_20.shape[0]*train_ratio)\n",
    "    \n",
    "    df_train = df4_explicit_20.iloc[:rows_in_split1]\n",
    "    df_test = df4_explicit_20.iloc[rows_in_split1:]\n",
    "    \n",
    "    df_test = df_test[(df_test['user_id'].isin(set(df_train['user_id']))) & (df_test['book_id'].isin(set(df_train['book_id'])))]\n",
    "    \n",
    "    \n",
    "    df_train_trans = dict()\n",
    "    df_test_trans = dict()\n",
    "    \n",
    "    for i in ['user_id', 'book_id']:\n",
    "        cat_encode = LabelEncoder()\n",
    "        df_train_trans[i] = cat_encode.fit_transform(df_train[i].values)\n",
    "        df_test_trans[i] = cat_encode.transform(df_test[i].values)\n",
    "      \n",
    "    \n",
    "    ratings = dict()\n",
    "    cat_encode = LabelEncoder()\n",
    "    ratings['train'] = cat_encode.fit_transform(df_train['book_rating'])\n",
    "    ratings['test'] = cat_encode.transform(df_test['book_rating'])\n",
    "    \n",
    "    n_users = len(set(df_train_trans['user_id']))\n",
    "    n_books = len(set(df_train_trans['book_id']))\n",
    "    \n",
    "    train = coo_matrix((ratings['train'], (df_train_trans['user_id'], df_train_trans['book_id'])), shape = (n_users, n_books))\n",
    "    test = coo_matrix((ratings['test'], (df_test_trans['user_id'], df_test_trans['book_id'])), shape = (n_users, n_books))      \n",
    "    \n",
    "    return(train, test, df_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_raw = train_test_rawtrain(df4_explicit_20, 0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfm = LightFM(no_components = 100, learning_rate = 0.025, loss = 'warp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfm.fit(train, epochs = 10, num_threads = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score(lfm, train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score(lfm, test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = train_raw.pivot(index = 'user_id', columns = 'book_id', values = 'book_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val.fillna(0, inplace = True)\n",
    "train_val = train_val.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to give user ({user_id : counter}) and book ({book_id : title}) dictionary\n",
    "\n",
    "def user_book_dict(train_val, df2):\n",
    "    \n",
    "    user_ids = list(train_val.index)\n",
    "    user_dict = dict()\n",
    "    c = 0\n",
    "    \n",
    "    for i in user_ids:\n",
    "        user_dict[i] = c\n",
    "        c = c+1\n",
    "        \n",
    "    book_dict = dict()\n",
    "    for i in range(df2.shape[0]):\n",
    "        book_dict[df2.loc[i, 'book_id']] = df2.loc[i, 'title']\n",
    "        \n",
    "#     or use below to create book dictionary\n",
    "#     book_dict = dict(zip(df2['book_id'].values, df2['title'].values))\n",
    "        \n",
    "    return(user_dict, book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict, book_dict = user_book_dict(train_val, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to give liked books and recommended books for a specific user\n",
    "# threshold can be used to control the know books by user\n",
    "\n",
    "def topm_recommendation(user_id, lfm, train_val, user_dict, book_dict, threshold = 0):\n",
    "    \n",
    "    n_users, n_books =  train_val.shape\n",
    "    \n",
    "    user = user_dict[user_id]\n",
    "    \n",
    "    scores = pd.Series(lfm.predict(user, np.arange(n_books)))\n",
    "    scores.index = train_val.columns\n",
    "    \n",
    "    scores = list(scores.sort_values(ascending = False).index)\n",
    "    \n",
    "    known_books = list(train_val.loc[user_id][train_val.loc[user_id, :] > threshold].sort_values(ascending = False).index)\n",
    "   \n",
    "    scores = [i for i in scores if i not in known_books]\n",
    "    \n",
    "    known_books = list(pd.Series(known_books).apply(lambda x: book_dict[x]))\n",
    "    scores = list(pd.Series(scores).apply(lambda x: book_dict[x]))\n",
    "    \n",
    "    print(\"Liked books by user:\")\n",
    "    for i in known_books[:10]:\n",
    "        print(i)\n",
    "        \n",
    "    print(\"\\n Recommended books:\")    \n",
    "    for i in scores[:10]:\n",
    "        print(i)\n",
    "    \n",
    "    \n",
    "#     return (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topm_recommendation(254, lfm, train_val, user_dict, book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to give recommended users for specific item\n",
    "\n",
    "def users_as_per_item(train_val, lfm, book_id, n_users_for_book):\n",
    "    \n",
    "    n_users, n_books = train_val.shape\n",
    "    book_ids = train_val.columns\n",
    "    \n",
    "    scores = list(lfm.predict(np.arange(n_users), np.repeat(book_ids.searchsorted(book_id), n_users)))\n",
    "    users = np.argsort(scores)[::-1][:n_users_for_book]\n",
    "#     np.argsort()\n",
    "    \n",
    "    return(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_as_per_item(train_val, lfm, '002542730X', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "x = csr_matrix(lfm.item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df_item_simil = pd.DataFrame(cosine_similarity(x))\n",
    "df_item_simil.columns = df_item_simil.index = train_val.columns\n",
    "df_item_simil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to give bought-together items (similar items) for a specific item\n",
    "# For better results the main dataframe (df4_explicit_20) can further be filtered with the users and books with atleast 100 ratings. \n",
    "# So the prediction will me made based on the users who have bought and rated more books\n",
    "# and the books with more ratings (popular) \n",
    "\n",
    "def bought_together(item_similarity_matrix, item_id, book_dict):\n",
    "    \n",
    "    recommended_3_books = list(item_similarity_matrix.loc[item_id, :].sort_values(ascending = False).index[1:4])\n",
    "    \n",
    "    print('bought together with :', book_dict[item_id])\n",
    "    for i in recommended_3_books:\n",
    "        print(book_dict[i])\n",
    "#     return(recommended_3_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bought_together(df_item_simil, '0439139597', book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(book_dict.keys())[list(book_dict.values()).index('Harry Potter and the Goblet of Fire (Book 4)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
